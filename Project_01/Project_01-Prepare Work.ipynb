{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Prepear Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get original content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_content(path):\n",
    "    if not os.path.isfile(path):\n",
    "        print('Input error, please enter correct path!')\n",
    "        return None\n",
    "    else:\n",
    "        content = pd.read_csv(path, encoding='ansi', error_bad_lines=False)\n",
    "        content = content.fillna(' ')\n",
    "        news_content = content['content'].tolist()\n",
    "        return news_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'D:\\Assignment\\Project_01\\newsdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3214: DtypeWarning: Columns (0,40,41,42,43,44,45,46,47,48,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    }
   ],
   "source": [
    "original_content = get_original_content(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'（原标题：44岁女子跑深圳约会网友被拒，暴雨中裸身奔走……）\\n@深圳交警微博称：昨日清晨交警发现有一女子赤裸上身，行走在南坪快速上，期间还起了轻生年头，一辅警发现后赶紧为其披上黄衣，并一路劝说她。\\n那么事发时\\n到底都发生了些什么呢？\\n南都记者带您一起还原现场\\n南都记者在龙岗大队坂田中队见到了辅警刘青（发现女生的辅警），一位外表高大帅气，说话略带些腼腆的90后青年。\\n刘青介绍，6月16日早上7时36分，他正在环城南路附近值勤，接到中队关于一位女子裸身进入机动车可能有危险的警情，随后骑着小铁骑开始沿路寻找，大概花了十多分钟在南坪大道坂田出口往龙岗方向的逆行辅道上发现该女子。\\n女子身上一丝不挂地逆车流而行，时走时停，时坐时躺，险象环生。刘青停好小铁骑，和另外一名巡防员追了上去，发现女子的情绪很低落，话不多，刘青尝试和女子交流，劝说女子离开，可女子并不愿意接受，继续缓慢地往南坪快速路的主干道上走去。\\n此时路边上已经聚集了很市民围观，为了不刺激女子的情绪，刘青和巡防员一边盯着女子一边驱赶着围观的群众。\\n现场还原\\n从警方提供的一份视频了解到，16日早上7时25分，女子出现在坂雪岗大道与环城南路的监控视频中，此时女子还穿着白色的内裤，正沿着坂雪岗大道往南坪快速的方向缓慢地走着。\\n当时正值上班高峰期，十字路口的车流已经排起了长队。当女子出现时，路上的市民纷纷驻足观望，不少车辆也放慢了速度，但女子并不为市民观望停下脚步，依然缓慢走着。当女子行进到十字路口中间时，一辆大货车挡住了镜头，但是当女子再次出现镜头时，可以发现女子已经没穿内裤了，全身裸露继续朝着南坪快速方向走去。记者发现，视频中女子周围并没有人尾随或者上前劝止的市民。\\n一大清早路上看到这样的情况\\n恐怕大家都没办法淡定\\n面对这一情况\\n刘青表示，“一开始根本不敢看她，心里挺别扭，感觉很尴尬”，但当刘青跟随女子上了南坪快速路主干道时，女子作出了让人意想不到的举动，她突然靠近护栏要从上面跳下去，刘青赶忙冲上去拉住了女子的手，将其控制住并远离护栏。碍于女子没有穿衣服，刘青递上衣服，女子没接受还把衣服扔到排水沟里，继续往前走，没办法刘青只能紧紧拉着她的一只手跟在后面。\\n刘青一路上耐心地开导安慰她，但只听到她不断地重复着一句话“要是你也遭遇我的事，你也会这样的”，期间她还不时试图挣脱刘青的手要冲向护栏往下跳。\\n就这样，我被牵着走了大概十多分钟，天突然下起了大暴雨，雨大的连眼睛都睁不开”刘青继续说着，瞬间他们就被雨透了，但女子依然不愿意接受刘青的帮助，就继续冒着大雨往前走。\\n大概走了有四十分钟吧，女子突然停下来说“我想回家了”，然后女子也接受了刘青递过来的小黄衣，就出现了深圳微博上的照片，女子披着小黄衣，刘青小心翼翼地在旁边走着的场景。从南平快速下来后，刘青和巡防员将女子带到了附近的坂田派出所。\\n那姑娘到底是遭遇了什么样的事情\\n才会说\\n“要是你也遭遇我的事，你也会这样”\\n据警方透露，该女子姓陈，系湖北人，今年44岁，据家属反映其有精神病史。三天前，陈某从老家来深圳约会网友，但约会受挫导致情绪异常，女子遂产生轻生念头。\\n目前\\n陈某已经被送往深圳某精神病医院进行治疗\\n大大君只希望姑娘能早点康复\\n其实真爱的到来并不存在年龄的限制\\n你们说呢？\\n因善良的原因\\n一众网友纷纷为\\n交警暖男点ZAN\\n@弓常yan桦：就想问这个小哥哥有女票吗\\n@原谅我这一辈子浪荡不羁爱萨摩耶：有什么过不去的要轻生嘛？ 想想自己的家人。同时也感谢交警蜀黍\\n@火心聆听心灵：点赞交警\\n@中華云盾：警察……警察就是群众最需时申出援手\\n@Tomchlee：蜀黍帅！\\n@SJ-李赫海i：这个交警很暖有木有！\\n男子迷奸网友拍418个视频 女方从20岁到50岁不等\\n去年6月7号上午，淮安市涟水县公安局刑警大队突然接到了一个奇怪的报警电话，一名女子言语不清，声称自己遭到了侵害。女子、被侵害、言语不清，几个关键词令接到电话的民警瞬间紧张起来。\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_content[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Processing original content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    return ''.join(re.findall(r'[\\d|\\w]+', string))\n",
    "def cut(string):\n",
    "    return ' '.join(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sentence(para):\n",
    "    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)  # 英文省略号\n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)  # 中文省略号\n",
    "    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n",
    "    # 如果双引号前有终止符，那么双引号才是句子的终点，把分句符\\n放到双引号后，注意前面的几句都小心保留了双引号\n",
    "    para = para.rstrip()  # 段尾如果有多余的\\n就去掉它\n",
    "    # 很多规则中会考虑分号;，但是这里我把它忽略不计，破折号、英文双引号等同样忽略，需要的再做些简单调整即可。\n",
    "    return para.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_content_with_punctuation(original_content):\n",
    "    sentence_content = []\n",
    "    for news in original_content:\n",
    "        news = re.sub(r'\\n', '', news)\n",
    "        if news != '' and news != ' ':\n",
    "            temp_list = cut_sentence(news)\n",
    "            sentence_content.append(temp_list)\n",
    "    return sentence_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_content(content):\n",
    "    sentence_content = []\n",
    "    for news in content:\n",
    "        temp_list = []\n",
    "        for sentence in news:\n",
    "            temp = token(sentence)\n",
    "            if temp!= '':\n",
    "                temp_list.append(temp)\n",
    "        sentence_content.append(temp_list)\n",
    "    return sentence_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_content_with_punctuation = get_sentence_content_with_punctuation(original_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_content = get_sentence_content(sentence_content_with_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87165"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_content_with_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?',\n",
       " '\\u3000\\u3000巨丰早评：市场将再次探底\\u3000\\u3000【巨丰观点】\\u3000\\u3000周四大盘冲高回落，2500余只个股下跌。',\n",
       " '上证50、沪深300指数顽强收红。',\n",
       " '早盘大盘低开高走，展开反弹，沪指冲破120日均线压力位；午后大盘跳水，个股普跌。',\n",
       " '盘面上，保险、电力、银行、民航机场、券商、房地产、人工智能、迪士尼、网络安全等板块涨幅居前。',\n",
       " '雄安新区、福州新区、医疗器械、丝绸之路等跌幅居前。',\n",
       " '\\u3000\\u3000金融股全线大涨：保险板块涨3%：新华保险、中国太保、中国人寿涨4%，中国平安涨2%；西水股份、天茂集团盘中大涨7%以上。',\n",
       " '银行板块涨2%：招商银行大涨8%，贵阳银行、兴业银行、浦发银行、兴业银行等涨幅居前。',\n",
       " '金融股是A股纳入MSCI指数的受益者，后市可以逢低关注。',\n",
       " '\\u3000\\u3000盘中万达电影、复星医药等白马股闪崩，导致午后市场出现大幅跳水。',\n",
       " '盘后消息，银监会于6月中旬要求各家银行排查包括万达、海航集团、复星、浙江罗森内里在内数家企业的授信及风险分析，排查对象多是近年来海外投资比较凶猛、在银行业敞口较大的民营企业集团。',\n",
       " '\\u3000\\u3000巨丰投顾认为自5月以来，大盘已经走出了3重底的走势，并开启中级反弹行情。',\n",
       " '沪指在上证50及白马股推动下率先反弹，但遭遇60日、120日均线强压力而出现调整。',\n",
       " 'MSCI纳入A股后，沪深300指数创17个月新高，但2500余股下跌，市场分化明显。',\n",
       " '随着6月末市场流动性紧张的可能出现，市场将再次出现探底。',\n",
       " '建议投资者重点关注半年报大幅预增的错杀股和具备估值优势的大蓝筹。',\n",
       " '\\u3000\\u3000天信投资：尾盘跳水原因揭秘 伏击的品种曝光\\u3000\\u3000周四市场点评：\\u3000\\u3000沪深两市早盘纷纷低开，但是开盘之后权重板块崛起，其中保险和银行表现尤其明显，低矮动股指快速拉升，并顺势突破了60日均线和半年线的束缚；在主板拉升的过程中，市场的分化格局也较明显，题材板块和创业板表现相对较弱。',\n",
       " '不过虽然市场在早盘的上攻，但是成交量萎缩明教明显，所以这种上涨比较虚。',\n",
       " '果不其然，午后个股再度纷纷杀跌，同时股指也是顺势回落，沪市的半年线得而复失，形成长长的上影线；而创业板股指在回落的过程中失守5日均线的支撑。',\n",
       " '整体上周四市场全天保持宽幅震荡走势，尤其是沪市冲高回落。',\n",
       " '保险、银行、中字头、举牌等品种涨幅居前；钛金属、区块链、雄安新区、民营医院等品种领跌。',\n",
       " '\\u3000\\u3000今日市场预测：\\u3000\\u3000在周三收市的评论中，我们指出周四市场会出现阶段性的普涨行情，而周四早盘三大股指齐齐上涨，即使创业板股指涨幅较小，但是市场确实也给我们呈现的普涨格局。',\n",
       " '但是午后的跳水，包括创业板股指先下跌，随后沪指尾盘的快速下杀，使得市场从普涨瞬间到普跌，市场的大起大落来的非常刺激。',\n",
       " '从三大股指周四呈现给大家的K线组合来看，预计今日市场齐跌的概率较大，不过创业板合格题材板块或具备一定的抗跌性。',\n",
       " '\\u3000\\u3000短期行情判断：\\u3000\\u3000从大的环境上来看，市场目前本身不具备大面积和大空间的反弹基础，因为目前无论是从宏观面、货币基本面或者从国际经济和政治的角度来看，都不具备这样的条件，所以反应到市场中来，只能是结构性、局部性的投机性机会。',\n",
       " '而最近半个月以来，市场的走势也确实符合局部性、结构性投机的走势。',\n",
       " '\\u3000\\u3000周四市场沪指形成带长长上影线的倒锤阴线；创业板股指形成的是跌破5日和10日均线的中阴线，这种类型的K线形态，几乎都是市场开始调整的先兆，所以短期市场而言，悲观的情绪或升温。',\n",
       " '\\u3000\\u3000后市投资建议：\\u3000\\u3000短期建议投资者一定要控制好自身的仓位。',\n",
       " '中期继续看好题材板块的崛起，特别是次新股、高送转、重组股等等可以不断的去伏击，依旧具备超跌反弹的性质。']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_content_with_punctuation[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['巨丰早评市场将再次探底巨丰观点周四大盘冲高回落2500余只个股下跌',\n",
       " '上证50沪深300指数顽强收红',\n",
       " '早盘大盘低开高走展开反弹沪指冲破120日均线压力位午后大盘跳水个股普跌',\n",
       " '盘面上保险电力银行民航机场券商房地产人工智能迪士尼网络安全等板块涨幅居前',\n",
       " '雄安新区福州新区医疗器械丝绸之路等跌幅居前',\n",
       " '金融股全线大涨保险板块涨3新华保险中国太保中国人寿涨4中国平安涨2西水股份天茂集团盘中大涨7以上',\n",
       " '银行板块涨2招商银行大涨8贵阳银行兴业银行浦发银行兴业银行等涨幅居前',\n",
       " '金融股是A股纳入MSCI指数的受益者后市可以逢低关注',\n",
       " '盘中万达电影复星医药等白马股闪崩导致午后市场出现大幅跳水',\n",
       " '盘后消息银监会于6月中旬要求各家银行排查包括万达海航集团复星浙江罗森内里在内数家企业的授信及风险分析排查对象多是近年来海外投资比较凶猛在银行业敞口较大的民营企业集团',\n",
       " '巨丰投顾认为自5月以来大盘已经走出了3重底的走势并开启中级反弹行情',\n",
       " '沪指在上证50及白马股推动下率先反弹但遭遇60日120日均线强压力而出现调整',\n",
       " 'MSCI纳入A股后沪深300指数创17个月新高但2500余股下跌市场分化明显',\n",
       " '随着6月末市场流动性紧张的可能出现市场将再次出现探底',\n",
       " '建议投资者重点关注半年报大幅预增的错杀股和具备估值优势的大蓝筹',\n",
       " '天信投资尾盘跳水原因揭秘伏击的品种曝光周四市场点评沪深两市早盘纷纷低开但是开盘之后权重板块崛起其中保险和银行表现尤其明显低矮动股指快速拉升并顺势突破了60日均线和半年线的束缚在主板拉升的过程中市场的分化格局也较明显题材板块和创业板表现相对较弱',\n",
       " '不过虽然市场在早盘的上攻但是成交量萎缩明教明显所以这种上涨比较虚',\n",
       " '果不其然午后个股再度纷纷杀跌同时股指也是顺势回落沪市的半年线得而复失形成长长的上影线而创业板股指在回落的过程中失守5日均线的支撑',\n",
       " '整体上周四市场全天保持宽幅震荡走势尤其是沪市冲高回落',\n",
       " '保险银行中字头举牌等品种涨幅居前钛金属区块链雄安新区民营医院等品种领跌',\n",
       " '今日市场预测在周三收市的评论中我们指出周四市场会出现阶段性的普涨行情而周四早盘三大股指齐齐上涨即使创业板股指涨幅较小但是市场确实也给我们呈现的普涨格局',\n",
       " '但是午后的跳水包括创业板股指先下跌随后沪指尾盘的快速下杀使得市场从普涨瞬间到普跌市场的大起大落来的非常刺激',\n",
       " '从三大股指周四呈现给大家的K线组合来看预计今日市场齐跌的概率较大不过创业板合格题材板块或具备一定的抗跌性',\n",
       " '短期行情判断从大的环境上来看市场目前本身不具备大面积和大空间的反弹基础因为目前无论是从宏观面货币基本面或者从国际经济和政治的角度来看都不具备这样的条件所以反应到市场中来只能是结构性局部性的投机性机会',\n",
       " '而最近半个月以来市场的走势也确实符合局部性结构性投机的走势',\n",
       " '周四市场沪指形成带长长上影线的倒锤阴线创业板股指形成的是跌破5日和10日均线的中阴线这种类型的K线形态几乎都是市场开始调整的先兆所以短期市场而言悲观的情绪或升温',\n",
       " '后市投资建议短期建议投资者一定要控制好自身的仓位',\n",
       " '中期继续看好题材板块的崛起特别是次新股高送转重组股等等可以不断的去伏击依旧具备超跌反弹的性质']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_content[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news-sentence-with-punctuation-cut.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for news in sentence_content_with_punctuation:\n",
    "        for sentence in news:\n",
    "            f.write(sentence + '\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news-sentence-cut.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for news in sentence_content:\n",
    "        for sentence in news:\n",
    "            f.write(sentence + '\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Word and Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_word_content(content):\n",
    "    temp_sentence = []\n",
    "    result_sentence = []\n",
    "    \n",
    "    temp_word = []\n",
    "    result_word = []\n",
    "    \n",
    "    for news in content:\n",
    "        for sentence in news:\n",
    "            cut = jieba.lcut(sentence)\n",
    "            \n",
    "            temp_word.append(' '.join(cut))\n",
    "            temp_sentence.append(cut)\n",
    "            \n",
    "        result_sentence.append(temp_sentence)\n",
    "\n",
    "        result_word.append(' '.join(temp_word))\n",
    "        temp_sentence = []\n",
    "        temp_word = []\n",
    "        temp = []\n",
    "    return result_sentence, result_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.176 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "sentence_word_content, word_content = get_sentence_word_content(sentence_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['此外',\n",
       "  '自',\n",
       "  '本周',\n",
       "  '6',\n",
       "  '月',\n",
       "  '12',\n",
       "  '日起',\n",
       "  '除',\n",
       "  '小米',\n",
       "  '手机',\n",
       "  '6',\n",
       "  '等',\n",
       "  '15',\n",
       "  '款',\n",
       "  '机型',\n",
       "  '外',\n",
       "  '其余',\n",
       "  '机型',\n",
       "  '已',\n",
       "  '暂停',\n",
       "  '更新',\n",
       "  '发布',\n",
       "  '含',\n",
       "  '开发',\n",
       "  '版',\n",
       "  '体验版',\n",
       "  '内测',\n",
       "  '稳定版',\n",
       "  '暂不受',\n",
       "  '影响',\n",
       "  '以',\n",
       "  '确保',\n",
       "  '工程师',\n",
       "  '可以',\n",
       "  '集中',\n",
       "  '全部',\n",
       "  '精力',\n",
       "  '进行',\n",
       "  '系统优化',\n",
       "  '工作'],\n",
       " ['有人', '猜测', '这', '也', '是', '将', '精力', '主要', '用到', 'MIUI9', '的', '研发', '之中'],\n",
       " ['MIUI8',\n",
       "  '去年',\n",
       "  '5',\n",
       "  '月',\n",
       "  '发布',\n",
       "  '距今已有',\n",
       "  '一年',\n",
       "  '有余',\n",
       "  '也',\n",
       "  '是',\n",
       "  '时候',\n",
       "  '更新换代',\n",
       "  '了'],\n",
       " ['当然', '关于', 'MIUI9', '的', '确切', '信息', '我们', '还是', '等待', '官方消息']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_word_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_word_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外 自 本周 6 月 12 日起 除 小米 手机 6 等 15 款 机型 外 其余 机型 已 暂停 更新 发布 含 开发 版 体验版 内测 稳定版 暂不受 影响 以 确保 工程师 可以 集中 全部 精力 进行 系统优化 工作 有人 猜测 这 也 是 将 精力 主要 用到 MIUI9 的 研发 之中 MIUI8 去年 5 月 发布 距今已有 一年 有余 也 是 时候 更新换代 了 当然 关于 MIUI9 的 确切 信息 我们 还是 等待 官方消息'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news-sentence-word-cut.txt', 'w', encoding='utf-8') as f:\n",
    "    for news in sentence_word_content:\n",
    "        for sentence in news:\n",
    "            for word in sentence:\n",
    "                f.write(word + ' ')\n",
    "            f.write('\\n')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news-word-cut.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for news_i in word_content:\n",
    "        f.write(news_i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_word2vec= Word2Vec(LineSentence('news-word-cut.txt'), size=35, workers=8, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('nn2014', 0.6896932721138),\n",
       " ('nnnnnn2016', 0.6849324703216553),\n",
       " ('时及', 0.6829358339309692),\n",
       " ('月京基', 0.6749576330184937),\n",
       " ('日诺列加', 0.6702944040298462),\n",
       " ('nnnn2013', 0.6642739176750183),\n",
       " ('nnnn2012', 0.6477642059326172),\n",
       " ('nn2015', 0.6403661370277405),\n",
       " ('环蒸成', 0.6362966895103455),\n",
       " ('nn2016', 0.6352211236953735)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_word2vec.most_similar('3743', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_word2vec.save(\"./Word2vec_model.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(func):\n",
    "    cache = {}\n",
    "\n",
    "    def _wrap(*args): ## ? *args, **kwargs\n",
    "        if args in cache: result = cache[args]\n",
    "        else:\n",
    "            result = func(*args)\n",
    "            cache[args] = result\n",
    "        return result\n",
    "    return _wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def get_related_words_first(input_word, model):\n",
    "    return [word for word, val in model.most_similar(input_word, topn=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_words(initial_words, model):\n",
    "    unseen = initial_words\n",
    "    \n",
    "    seen = defaultdict(int)\n",
    "    \n",
    "    max_size = 500\n",
    "    \n",
    "    while unseen and len(seen) < max_size:\n",
    "        if len(seen) % 50 == 0: \n",
    "            print('seen length : {}'.format(len(seen)))\n",
    "        \n",
    "        now_word = unseen.pop(0)\n",
    "        \n",
    "        new_append = get_related_words_first(now_word, model)\n",
    "        \n",
    "        unseen += new_append\n",
    "        \n",
    "        seen[now_word] += 1\n",
    "    return seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen length : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen length : 50\n",
      "seen length : 100\n",
      "seen length : 150\n",
      "seen length : 200\n",
      "seen length : 200\n",
      "seen length : 250\n",
      "seen length : 250\n",
      "seen length : 300\n",
      "seen length : 350\n",
      "seen length : 400\n",
      "seen length : 450\n"
     ]
    }
   ],
   "source": [
    "related_word = get_related_words(['说', '表示'], news_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_word = sorted(related_word.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('说', 75),\n",
       " ('指出', 74),\n",
       " ('表示', 73),\n",
       " ('认为', 69),\n",
       " ('坦言', 68),\n",
       " ('透露', 62),\n",
       " ('看来', 53),\n",
       " ('告诉', 49),\n",
       " ('提到', 45),\n",
       " ('所说', 43)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_word_use = [word for word, val in related_word if val> 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['说', '指出', '表示', '认为', '坦言', '透露', '看来', '告诉', '提到', '所说']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_word_use[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('related_word.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in related_word_use:\n",
    "        f.write(word + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
